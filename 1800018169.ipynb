{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1800018169.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM0/q4zPXnobzk3mQgoFEU9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZainAhmadTaufik/TBigData/blob/master/1800018169.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wVVSaI3jNKp",
        "colab_type": "text"
      },
      "source": [
        "# **Proses EDA (Exploratory Data Analysis) pada Dataset lelang-id-2017-2018**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08TXy4lyjOBm",
        "colab_type": "text"
      },
      "source": [
        "Proses EDA seharusnya dilakukan untuk semua kolom supaya informasi data, sebaran data diketahui sehingga dapat dilakukan pre-processing sebelum data diolah menggunakan pemrosesan Big Data (misal MapReduce, Transformations dan Actions pada RDD, DataFrame, SpratSQL maupun SparkML(Machine Learning))\n",
        "\n",
        "Pada proses EDA ini, saya akan memproses data pada kolom nama_paket, hasil_lelang, dan tahun_anggaran. Anda di harapkan melakukan proses EDA terhadap data sesuai kolom-kolom yang ada pada dataset yang anda pilih"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmMNUTnajUVa",
        "colab_type": "text"
      },
      "source": [
        "# **1. Instalasi Spark pada Google Colab**\n",
        "\n",
        "Kode di bawah ini hanya dijalankan **satu kali saja** saat runtime pertama kali dijalankan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7SHo2JSkMD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "! wget -q https://downloads.apache.org/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
        "! tar xf spark-2.4.6-bin-hadoop2.7.tgz\n",
        "! pip install -q findspark\n",
        "! pip install pyspark_dist_explore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-lmw6AAkd3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHgT3JiNjZgJ",
        "colab_type": "text"
      },
      "source": [
        "# **2. Import library Spark yang sudah diinstal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTImzGs5krmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init(\"spark-2.4.6-bin-hadoop2.7\")# SPARK_HOME\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "from pyspark.sql.functions import col, avg\n",
        "from matplotlib import pyplot as plt\n",
        "from pyspark_dist_explore import Histogram, hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k98wczMJja31",
        "colab_type": "text"
      },
      "source": [
        "# **3. Inisialisasi SparkContext dan SparkSession**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Minxw8hEkuu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc = spark.sparkContext\n",
        "spark = SparkSession(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKA9VQhcjeiA",
        "colab_type": "text"
      },
      "source": [
        "# **4. Load Dataset**\n",
        "\n",
        "Dataset berupa file CSV di load. lokasi file csv sama dengan lokasi file kode program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIYOiqBk9Uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = spark.read.csv('.csv', header=True, inferSchema=True)\n",
        "data.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2doetohjh-Z",
        "colab_type": "text"
      },
      "source": [
        "# **5. Proses EDA**\n",
        "\n",
        "Pertama kita cek jumlah total data lelang yang ada pada dataset lelang-id-2017-2018"
      ]
    }
  ]
}